```python
# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
```
# Metadata Explorer

This project is designed to explore metadata generated by Gemini using Google Cloud Platform. There are two resources in this repo: 

<table>
<tr>
    <th style="text-align: center;">Item</th>
    <th style="text-align: center;">Description</th>
</tr>
<tr> 
    <td> Notebook</td>
    <td> A metadata creation pipeline in a colab notebook.</td>
</tr>
<tr> 
    <td> Metadata Explorer</td>
    <td> A sample streamlit app that shows metadata generated by gemini.</td>
</tr>

<tr></tr>
</table>

## Notebook

We've added a notebook that showcases how Gemini works with multi-modal inputs to generate insights and support customers that have either audio, image, or video assets. More info on Gemini's multi-modality [here](https://cloud.google.com/use-cases/multimodal-ai?hl=en).

Specifically the scenario we are showcasing in this notebook is the creation of a pipeline that given a set of assets in a Google Cloud Storage bucket is able to create metadata that is accurate and informative about these assets.

## Running the App

### Prerequisites

1. Create the resources as required in the config.yaml file and their corresponding items in the gcp project.
2. Run the metadata ingestion pipeline as per the notebook.

Choose one of the following options to deploy the streamlit application once you've finished generating your metadata.

### Option A - Locally

1. Set up your application credentials by storing your json export of your service account key in secrets/credentials.json.
2. Create a python virtual env
```shell
python3 -m venv .venv
```
3. Run the shell command that launches your streamlit app
```shell
sh run.sh
```

### Option B - Deploying to Cloud Run

To build a container and deploy it to cloud run we will need to: 

1. Create your environment dependent config file.
2. Build the container.
3. Push the container to Artifact Registry.
4. Deploy the container to Cloud Run.

Running the following commands in Cloud Shell will make authentication process easier.

#### Environment variables

```shell

export PROJECT_IDENTIFIER='project_id'
export CONTAINER_VERSION='v1.0'
export CONTAINER_NAME='metadata_explorer'
export IMAGE_URI=us.gcr.io/$PROJECT_IDENTIFIER/$CONTAINER_NAME:$CONTAINER_VERSION
export REGION='us-central1'

```

Change the variables accordingly.

#### Build the container
```shell

docker build -t $IMAGE_URI .

```
Once that is done push it to the Artifact Registry: 

```shell

docker push $IMAGE_URI

```

#### Push new version of the container

```shell
export CLOUDRUN_SERVICE=metadata-explorer
```

```shell

gcloud run deploy $CLOUDRUN_SERVICE \
--image=us.gcr.io/$PROJECT_IDENTIFIER/$CONTAINER_NAME:$CONTAINER_VERSION \
--region=$REGION \
--project=$PROJECT_IDENTIFIER \
 && gcloud run services update-traffic $CLOUDRUN_SERVICE --to-latest --region=$REGION
 
```

## Disclaimer

This repository itself is not an officially supported Google product. The code in this repository is for demonstrative purposes only.